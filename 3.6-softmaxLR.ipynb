{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "\n",
    "import d2lzh_pytorch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据\n",
    "\n",
    "这个jupyterlab太多包没有了（自己的电脑上并没有出现这个问题）...为了方便重写函数\n",
    "\n",
    "根据官方教程，windows系统上num_workers设置为大于1会出现问题：  \n",
    "If running on Windows and you get a BrokenPipeError, try setting\n",
    "the num_worker of torch.utils.data.DataLoader() to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fmnist_dataset(batch_size):\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=True, download=True, transform=transforms.ToTensor())\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=False, download=True, transform=transforms.ToTensor())\n",
    "    \n",
    "    if sys.platform.startswith('win'):  \n",
    "        num_workers = 0\n",
    "    else:\n",
    "        num_workers = 4\n",
    "    \n",
    "    train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    return train_iter, test_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_iter, test_iter = load_fmnist_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input = 28 * 28\n",
    "num_output = 10\n",
    "\n",
    "W = torch.normal(0, 0.01, size=(num_input, num_output), dtype=torch.float)\n",
    "b = torch.zeros(num_output, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置模型参数梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现softmax运算\n",
    "\n",
    "首先了解torch.sum()的具体使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 7, 9]])\n",
      "tensor([[ 6],\n",
      "        [15]])\n",
      "tensor([5, 7, 9])\n",
      "tensor([ 6, 15])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# dim=0，按行求和的意思是：结果的行数->1，不同行同一列元素之间求和\n",
    "print(X.sum(dim=0, keepdim=True))\n",
    "# dim=1，按列求和，则是同一行不同列元素求和\n",
    "print(X.sum(dim=1, keepdim=True))\n",
    "\n",
    "# keepdim=False，二维张量求和后自动转化为一维张量，其他类似\n",
    "print(X.sum(dim=0, keepdim=False))\n",
    "print(X.sum(dim=1, keepdim=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用函数定义softmax运算\n",
    "\n",
    "我们的W定义的是784X10，因此样本是28X28也就应该转化为1X784，最后运算得到的结果为1X10，1行10列，因此应该令dim=1求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = X.exp()\n",
    "    partition = X_exp.sum(dim=1, keepdim=True)\n",
    "    return X_exp / partition  # 此处用到广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用一个小例子看看我们定义的函数是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8467, 0.3811, 0.4029, 0.5119, 0.8394],\n",
      "        [0.8183, 0.4189, 0.2610, 0.6749, 0.2511]])\n",
      "tensor([[0.2514, 0.1578, 0.1613, 0.1799, 0.2496],\n",
      "        [0.2720, 0.1824, 0.1558, 0.2356, 0.1542]]) tensor([1., 1.])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((2, 5))\n",
    "\n",
    "X_prob = softmax(X)\n",
    "\n",
    "print(X)\n",
    "print(X_prob, X_prob.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义softmax回归的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    return softmax(torch.mm(X.view(-1, num_input), W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数\n",
    "\n",
    "这里使用gather()来实现交叉熵。这里，如何理解gather()这个函数是非常重要的问题。\n",
    "\n",
    "torch.gather(input, dim, index, out=None, sparse_grad=False) → Tensor\n",
    "\n",
    "官方解释是：Gathers values along an axis specified by dim.\n",
    "\n",
    "dim代表指定的维度。最终输出结果的size应该与index完全相同。\n",
    "\n",
    "简单理解为：最终返回一个与index的size相同的tensor，其中dim指定的维度的index被gather中的index替代，其他维不变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000],\n",
       "        [0.5000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y = torch.LongTensor([0, 2])\n",
    "\n",
    "y_hat.gather(1, y.view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下定义交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat.gather(1, y.view(-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引入评价指标：准确率\n",
    "\n",
    "y_hat.argmax(dim=1)返回每行中最大的值，做判断后得到一个ByteTensor，因此需要求float()转化为浮点数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(dim=1) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(y_hat, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评价模型net在data_iter上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for X, y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "net是随机初始化的，因此预测概率相当于随机猜猜对的概率（0.1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0657\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_accuracy(test_iter, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
