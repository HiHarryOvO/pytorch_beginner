{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在官方tutorial以及《动手学》的书中，torch.empty()生成的张量中并不全为0，按官方说法是，\"values that were in the allocated memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.rand()随机初始化，其中的值服从U(0,1)\n",
    "\n",
    "torch.randn()生成服从N(0,1)的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3769, 0.3294, 0.2281, 0.8311],\n",
      "        [0.5279, 0.5819, 0.0604, 0.4873],\n",
      "        [0.2259, 0.7543, 0.8833, 0.4825]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]]) tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 3, dtype=torch.long)\n",
    "y = torch.ones(2, 2, dtype=torch.float)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Tensor.new_ones()生成新的张量，需要指定新张量的size，默认继承torch.dtype以及torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "z = y.new_ones(3)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch中加法的两种形式\n",
    "\n",
    "torch.add(input, other, out=None)\n",
    "\n",
    "$out = input + other$\n",
    "\n",
    "注：out需要提前声明，但似乎并不在意out原本的size是什么样的？见下方代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8194, 1.9275, 1.7167, 1.8103],\n",
      "        [1.7587, 1.0751, 1.2124, 1.3455],\n",
      "        [1.8625, 1.9173, 1.1703, 1.0286]])\n",
      "tensor([[1.8194, 1.9275, 1.7167, 1.8103],\n",
      "        [1.7587, 1.0751, 1.2124, 1.3455],\n",
      "        [1.8625, 1.9173, 1.1703, 1.0286]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 4)\n",
    "y = torch.rand(3, 4)\n",
    "\n",
    "print(x + y)\n",
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里result本来的size并不和x及y相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8194, 1.9275, 1.7167, 1.8103],\n",
       "        [1.7587, 1.0751, 1.2124, 1.3455],\n",
       "        [1.8625, 1.9173, 1.1703, 1.0286]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.empty(1, 2)\n",
    "torch.add(x, y, out=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8194, 1.9275, 1.7167, 1.8103],\n",
       "        [1.7587, 1.0751, 1.2124, 1.3455],\n",
       "        [1.8625, 1.9173, 1.1703, 1.0286]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：PyTorch操作inplace版本都有后缀_, 例如x.copy_(y), x.t_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8194, 1.9275, 1.7167, 1.8103],\n",
      "        [1.7587, 1.0751, 1.2124, 1.3455],\n",
      "        [1.8625, 1.9173, 1.1703, 1.0286]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch索引操作不创建新内存。索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8194, 2.9275, 2.7167, 2.8103])\n",
      "tensor([2.8194, 2.9275, 2.7167, 2.8103])\n"
     ]
    }
   ],
   "source": [
    "x = y[0, :]\n",
    "x += 1\n",
    "\n",
    "print(x)\n",
    "print(y[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：torch.Tensor.view()同样也是共享内存的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12]) torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "y_1 = y.view(12)\n",
    "y_2 = y.view(2, -1)\n",
    "\n",
    "print(y_1.size(), y_2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了解决共享内存的问题，建议使用torch.Tensor.clone().view()\n",
    "\n",
    "使用clone还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8194, 2.9275, 2.7167, 2.8103, 1.7587, 1.0751, 1.2124, 1.3455, 1.8625,\n",
      "        1.9173, 1.1703, 1.0286])\n",
      "tensor([[1.8194, 1.9275, 1.7167, 1.8103],\n",
      "        [0.7587, 0.0751, 0.2124, 0.3455],\n",
      "        [0.8625, 0.9173, 0.1703, 0.0286]])\n"
     ]
    }
   ],
   "source": [
    "y_cp = y.clone().view(12)\n",
    "\n",
    "y -= 1\n",
    "print(y_cp)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9088])\n",
      "1.908822774887085\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
